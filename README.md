# VSOSH_RNN_PROJECT
`README.md` - Инструкция по использованию продукта\
`Word2Vec_traning.ipynb` - Модули для обучения модели Word2Vec на тексте\
`RNN.pth` - Веса обученной модели RNN\
`W2V.model` - Веса обученной модели Word2Vec\
`RNN_traning_and_Using.ipynb` - Модули модели RNN со следующим **_функционалом_**:
- Загрузка даннах для обучения
- Разделение на обучающую выборку и тестовую
- Перевод вычислений и данных на графический процессор
- Инициализация модели
- Обучение модели
- Оценка модели (с усредением, если не один слой выходной и вычисление выбранных метрик оценки)
- Сохранение весов модели

Использование:
- Объявление необходимых функций и классов
- Загрузка весов
- Получение строчки от пользователя
- Вычисление предсказания, преобразование и вывод

Каждый модуль находится в отдельных ячейках кода для логического разделения.

# Использование кода в виде Jupyter Notebook
1) Скачать файлы с GitHub
2) Поместить их в одну папку
3) Открыть файл `RNN_traning_and_Using.ipynb` (для удобства можно открыть в VS code или в Jupyter Notebook)
4) Перейти к часте `Using and testing`
5) По очереди выполняем все ячейк кода:
   - Подключение библиотек
   - Инициализиция классов и функций, перевод моделей в режим использования
   - Загрузка весов для двух моделей
   - Получение предсказаний для введённого значения

# Создание файла .exe для Windows
Для удобства обычных пользователей можно сделать один исполняемый файл включающий в себя все веса и библиотеки.
Этапы создания файла .exe:
1) ```
   pip3 install pyinstaller
   ```
2) ```
   pyinstaller --onefile --add-data "RNN.pth;." --add-data "W2V.model;." For_user.py
   ```
3) Перейти в папку `dist` и выполнить файл `For_user`

# Параметры модели по умолчанию
`Параметры модели:`
|Название|Значение|
|-----|----|
|Количество скрытых слоёв|2|
|Количество нейронов во входном слое|100|
|Количество нейронов в скрытом слое|45|
|Архитектура|LSTM|
|Функция потерь|Среднеквадратичная ошибка - MSELoss|
|Оптимизатор|Адаптивный оптимизатор - Adam|
|Функция активации|Sigmoid|
|Регуляризация|Dropout и L2-регуляризация|
|Количество эпох|7-10|
|Размер батча|32|

# Формулы RNN
`Формулы RNN`
```math
h_t = tanh(W_{xh}x_t + W_{hh}h_{t-1} + b_h)
```
```math
y_t = W_{hy}h_t + b_y
```

`Обозначения к Формулам:`\
$`W_{xh}\ –\ матрица\ весов\ между\ входным\ слоем\ и\ скрытым`$\
$`W_{hh}\ –\ матрица\ весов\ между\ старым\ скрытым\ состоянием\ и\ новым`$\
$`B_h\ –\ матрица\ смещений\ для\ расчёта\ скрытого\ состояния`$\
$`W_{hy}\ –\ матрица\ весов\ между\ скрытым\ слоем\ и\ выходным`$\
$`B_y\ –\ матрица\ смещений\ для\ расчёта\ выходных\ значений`$

# Зависимости
- python (предпочтительнее 3.11)
- gensim
- torch
- numpy
- pandas
- nltk
- sklearn
